The proposal arhitecture has come up by reviewing the last papers which introduced to:

- Samba: Leveraging to expand the context
- TTT using RNN: Fine tune the attention mechanism
- GrokFast: optimize and generalize better the model

The architecture has been shared to EurekaLabs and lucidrains to have some help hehe

![image](https://github.com/user-attachments/assets/ac98a99e-1119-406d-98d1-37f61fc1969f)

Ofc, at the last of the chain needs to be inserted Prompt Engineering techniques so that the model get accurated result.
